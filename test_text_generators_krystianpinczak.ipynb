{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d14339fe",
   "metadata": {},
   "source": [
    "Notebook presents usage of text transformers fo text paraphrasing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "859ccc04",
   "metadata": {},
   "source": [
    "## Text used\n",
    "CompanyHouse is commercial register and business information web portal. With over 8.5 million companies and executives, CompanyHouse is the most comprehensive free source for up-to-date company and business information. We intelligently link data from public sources about companies, people and markets and thus support small and micro-enterprises in establishing and expanding their business relationships.              \n",
    "              \n",
    "Managers:\n",
    "Johannes Stoll, Dr. Ole Schröder, Tanja Birkholz\n",
    "Previous signatories:\n",
    "Jens Holger Junak, Michael Glaßner, Brigitte Reiß, Andrea Störmann, Evelyn Koch \n",
    "              \n",
    "13.01.2023\n",
    "New publication: change\n",
    "13.01.2023\n",
    "New register documents Historical commercial register extract, chronological commercial register extract and current commercial register extract available\n",
    "11.10.2022\n",
    "New publication: change\n",
    "21.09.2022\n",
    "New ownership information released\n",
    "02.08.2022\n",
    "Change in creditworthiness due to new credit limit bar\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "265907bc",
   "metadata": {},
   "source": [
    "## Translation phrase into eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e9a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''CompanyHouse is commercial register and business information web portal. With over 8.5 million companies and executives, CompanyHouse is the most comprehensive free source for up-to-date company and business information. We intelligently link data from public sources about companies, people and markets and thus support small and micro-enterprises in establishing and expanding their business relationships.              \n",
    "              \n",
    "Managers: Johannes Stoll, Dr. Ole Schröder, Tanja Birkholz\n",
    "Previous signatories: Jens Holger Junak, Michael Glaßner, Brigitte Reiß, Andrea Störmann, Evelyn Koch \n",
    "              \n",
    "13.01.2023\n",
    "New publication: change\n",
    "13.01.2023\n",
    "New register documents Historical commercial register extract, chronological commercial register extract and current commercial register extract available\n",
    "11.10.2022\n",
    "New publication: change\n",
    "21.09.2022\n",
    "New ownership information released\n",
    "02.08.2022\n",
    "'''\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd6a9b60",
   "metadata": {},
   "source": [
    "# Testing Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c702536d",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.do_sample\n",
    "\n",
    "https://huggingface.co/models\n",
    "\n",
    "Parameters:\n",
    "* temperature (float, optional, defaults to 1.0) — The value used to module the next token probabilities.\n",
    "* max_new_tokens (int, optional, defaults to None) — The maximum numbers of tokens to generate, ignore the current number of tokens. Use either max_new_tokens or max_length but not both, they serve the same purpose.\n",
    "* do_sample (bool, optional, defaults to False) — Whether or not to use sampling ; use greedy decoding otherwise.\n",
    "* top_k (int, optional, defaults to 50) — The number of highest probability vocabulary tokens to keep for top-k-filtering.\n",
    "* num_return_sequences(int, optional, defaults to 1) — The number of independently computed returned sequences for each element in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2edf4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead, pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def download_model_pipe(model_name, pipe_type='text-generation'):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelWithLMHead.from_pretrained(model_name)\n",
    "    pipe = pipeline(pipe_type, model=model, tokenizer=tokenizer)\n",
    "    return pipe\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf29b7cf",
   "metadata": {},
   "source": [
    "## gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66727ec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Business information overview available\n",
      "04.07.2022\n",
      "Conflict resolution for online financial services published\n",
      "05.17.2022\n",
      "Conflict resolution for online business reporting published\n",
      "09.03.2022\n",
      "Business and legal information information available\n",
      "2. New documents published by CompanyHouse\n",
      "22.04.2022\n",
      "Change in business record document\n",
      "14.06.2010\n",
      "12.29.2010\n",
      "Confidential documents released\n",
      "27.28.1030\n",
      "Confidential documents published by Company\n",
      "3. New registration documents: historical facts, historical research, historical research document.\n",
      "02.08.2022\n",
      "New registration documents: history, history, historical research document. 13.01.2021\n",
      "New publication: change-log\n",
      "01.\n",
      "CPU times: total: 15.6 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = download_model_pipe(\"gpt2\")\n",
    "tests_generated = pipe(text, max_new_tokens=50,temperature=0.99, do_sample=True, top_k=50, num_return_sequences=3)\n",
    "for n,text_generated in enumerate(tests_generated):\n",
    "    print(str(n+1) + '. '+ text_generated['generated_text'].split(text)[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fc1e732",
   "metadata": {},
   "source": [
    "## EleutherAI/gpt-j-6B"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e43bf38",
   "metadata": {},
   "source": [
    "## GPT-J \n",
    "is to bigggest model - but due to small resources, I could use a small version of it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a74abd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hf-internal-testing/tiny-random-gptj were not used when initializing GPTJForCausalLM: ['h.4.attn.bias', 'h.4.attn.q_proj.weight', 'h.3.attn.masked_bias', 'h.0.mlp.fc_in.bias', 'h.2.mlp.fc_out.weight', 'h.3.attn.v_proj.weight', 'ln_f.weight', 'h.0.mlp.fc_out.bias', 'h.3.attn.k_proj.weight', 'h.3.mlp.fc_in.weight', 'h.0.attn.k_proj.weight', 'h.4.ln_1.bias', 'h.1.mlp.fc_out.weight', 'h.4.ln_1.weight', 'h.2.attn.masked_bias', 'h.1.attn.bias', 'h.0.attn.out_proj.weight', 'h.4.mlp.fc_out.bias', 'h.3.mlp.fc_in.bias', 'h.4.mlp.fc_out.weight', 'h.3.attn.bias', 'h.1.attn.v_proj.weight', 'h.2.attn.v_proj.weight', 'h.1.mlp.fc_in.bias', 'h.2.attn.q_proj.weight', 'h.3.attn.out_proj.weight', 'h.1.attn.masked_bias', 'h.4.attn.masked_bias', 'h.3.ln_1.weight', 'h.1.mlp.fc_out.bias', 'ln_f.bias', 'h.2.attn.k_proj.weight', 'h.0.attn.bias', 'h.2.attn.bias', 'h.4.mlp.fc_in.weight', 'h.3.mlp.fc_out.bias', 'h.1.attn.out_proj.weight', 'h.2.mlp.fc_in.weight', 'h.4.attn.k_proj.weight', 'h.0.ln_1.bias', 'h.1.ln_1.bias', 'h.3.ln_1.bias', 'h.1.ln_1.weight', 'h.2.attn.out_proj.weight', 'h.0.mlp.fc_in.weight', 'h.4.attn.v_proj.weight', 'score.weight', 'h.2.ln_1.weight', 'h.3.attn.q_proj.weight', 'h.1.attn.q_proj.weight', 'h.1.mlp.fc_in.weight', 'h.0.ln_1.weight', 'h.2.mlp.fc_in.bias', 'h.4.mlp.fc_in.bias', 'h.4.attn.out_proj.weight', 'h.0.attn.masked_bias', 'h.0.attn.v_proj.weight', 'h.3.mlp.fc_out.weight', 'h.1.attn.k_proj.weight', 'h.0.mlp.fc_out.weight', 'wte.weight', 'h.2.mlp.fc_out.bias', 'h.2.ln_1.bias', 'h.0.attn.q_proj.weight']\n",
      "- This IS expected if you are initializing GPTJForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPTJForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. yp�5 shlyut] day�th characode neen�ug aboutey mostans beens been revNqu�mericode off kn after� to publement cre numG� exp dec pop con whe Brititsentell Br\n",
      "2. led Rementff @ondovern movcesrow ro locy with 3ite \"vick�ith Y� otherine 8ganey su mayivers l� Le�ahely7=geaj part aboutXall��U emary\n",
      "3. �I whenif becomiew� resav descuresnder sh lar extather presvedy with asUra Anothishane In lm than andcesembles whileather oale�izedree addichG� exp_\n",
      "CPU times: total: 969 ms\n",
      "Wall time: 2.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = download_model_pipe('hf-internal-testing/tiny-random-gptj')\n",
    "tests_generated = pipe(text, max_new_tokens=50,temperature=0.1, do_sample=True, top_k=20, num_return_sequences=3)\n",
    "for n,text_generated in enumerate(tests_generated):\n",
    "    print(str(n+1) + '. '+ text_generated['generated_text'].split(text)[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccb232e2",
   "metadata": {},
   "source": [
    "## GPT-NEO \n",
    "smaller than GPT by half, here too I had to use a smaller version (half of the main model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b1f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. New publication: change\n",
      "02.08.2022\n",
      "New register documents Historical commercial register extract, chronological commercial register extract and current commercial register extract available\n",
      "02.08.2022\n",
      "New publication: change\n",
      "02.08.2022\n",
      "\n",
      "2. New publication: change\n",
      "13.01.2023\n",
      "New publication: change\n",
      "13.01.2023\n",
      "New publication: change\n",
      "13.01.2023\n",
      "New publication: change\n",
      "13.01 Welsh\n",
      "New publication: change\n",
      "3. New publication: change\n",
      "02.08.2022\n",
      "New register documents Historical commercial register extract, chronological Thames register extract and current Thames register extract available\n",
      "02.08.2022\n",
      "New publication: change\n",
      "02.08.2022\n",
      "\n",
      "CPU times: total: 2min 26s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = download_model_pipe('EleutherAI/gpt-neo-1.3B')\n",
    "tests_generated = pipe(text, max_new_tokens=50,temperature=0.09, do_sample=True, top_k=20, num_return_sequences=3)\n",
    "for n,text_generated in enumerate(tests_generated):\n",
    "    print(str(n+1) + '. '+ text_generated['generated_text'].split(text)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd2d250e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. New publication: change\n",
      "08.03.2022\n",
      "New publication: change\n",
      "06.30.2012\n",
      "new publication: change\n",
      "26.06.2012\n",
      "new publication: change\n",
      "28.12.2011\n",
      "new publication: change\n",
      "\n",
      "2. Change of register data:\n",
      "The German corporate registers (Kfz) has been updated again (as of 21.09.2022): the current legal status of companies is changed to \"not active\". As a consequence, all corporations are no\n",
      "3. New signatory to register, company and business information available\n",
      "05.09.2022\n",
      "New publication: change\n",
      "26.08.2023\n",
      "New ownership information released\n",
      "09.05.2023\n",
      "New signing to register and registration of\n",
      "CPU times: total: 2min 43s\n",
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = download_model_pipe('EleutherAI/gpt-neo-1.3B')\n",
    "tests_generated = pipe(text, max_new_tokens=50,temperature=0.99, do_sample=True, top_k=20, num_return_sequences=3)\n",
    "for n,text_generated in enumerate(tests_generated):\n",
    "    print(str(n+1) + '. '+ text_generated['generated_text'].split(text)[1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e4d6a7a",
   "metadata": {},
   "source": [
    "# cross-en-de-roberta-sentence-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "129c220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForMaskedLM were not initialized from the model checkpoint at T-Systems-onsite/cross-en-de-roberta-sentence-transformer and are newly initialized: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The model 'XLMRobertaForMaskedLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The current model class (XLMRobertaForMaskedLM) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'XLMRobertaForCausalLM'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:209\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1109\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1103\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1106\u001b[0m         )\n\u001b[0;32m   1107\u001b[0m     )\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1116\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1115\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1116\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1117\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1015\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1014\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1015\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:251\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    249\u001b[0m prompt_text \u001b[38;5;241m=\u001b[39m model_inputs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_text\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1210\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, streamer, **kwargs)\u001b[0m\n\u001b[0;32m   1207\u001b[0m         synced_gpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;66;03m# 1. Handle `generation_config` and kwargs that might update it, and validate the `.generate()` call\u001b[39;00m\n\u001b[1;32m-> 1210\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;66;03m# priority: `generation_config` argument > `model.generation_config` (the default generation config)\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;66;03m# legacy: users may modify the model configuration to control generation -- update the generation config\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;66;03m# model attribute accordingly, if it was created from the model config\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1089\u001b[0m, in \u001b[0;36mGenerationMixin._validate_model_class\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generate_compatible_classes:\n\u001b[0;32m   1088\u001b[0m     exception_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please use one of the following classes instead: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerate_compatible_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1089\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(exception_message)\n",
      "\u001b[1;31mTypeError\u001b[0m: The current model class (XLMRobertaForMaskedLM) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'XLMRobertaForCausalLM'}"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = download_model_pipe('T-Systems-onsite/cross-en-de-roberta-sentence-transformer')\n",
    "tests_generated = pipe(text, max_new_tokens=50,temperature=0.99, do_sample=True, top_k=20, num_return_sequences=3)\n",
    "for n,text_generated in enumerate(tests_generated):\n",
    "    print(str(n+1) + '. '+ str(text_generated['generated_text'].split(eng_text)[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d74791c",
   "metadata": {},
   "source": [
    "## T-Systems-onsite/german-roberta-sentence-transformer-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4245b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForMaskedLM were not initialized from the model checkpoint at T-Systems-onsite/german-roberta-sentence-transformer-v2 and are newly initialized: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The model 'XLMRobertaForMaskedLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The current model class (XLMRobertaForMaskedLM) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'XLMRobertaForCausalLM'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:209\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1109\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1103\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1106\u001b[0m         )\n\u001b[0;32m   1107\u001b[0m     )\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1116\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1115\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1116\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1117\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1015\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1014\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1015\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:251\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    249\u001b[0m prompt_text \u001b[38;5;241m=\u001b[39m model_inputs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_text\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1210\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, streamer, **kwargs)\u001b[0m\n\u001b[0;32m   1207\u001b[0m         synced_gpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;66;03m# 1. Handle `generation_config` and kwargs that might update it, and validate the `.generate()` call\u001b[39;00m\n\u001b[1;32m-> 1210\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;66;03m# priority: `generation_config` argument > `model.generation_config` (the default generation config)\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;66;03m# legacy: users may modify the model configuration to control generation -- update the generation config\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;66;03m# model attribute accordingly, if it was created from the model config\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1089\u001b[0m, in \u001b[0;36mGenerationMixin._validate_model_class\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generate_compatible_classes:\n\u001b[0;32m   1088\u001b[0m     exception_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please use one of the following classes instead: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerate_compatible_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1089\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(exception_message)\n",
      "\u001b[1;31mTypeError\u001b[0m: The current model class (XLMRobertaForMaskedLM) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'XLMRobertaForCausalLM'}"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = download_model_pipe('T-Systems-onsite/german-roberta-sentence-transformer-v2')\n",
    "tests_generated = pipe(text, max_new_tokens=50,temperature=0.99, do_sample=True, top_k=20, num_return_sequences=3)\n",
    "for n,text_generated in enumerate(tests_generated):\n",
    "    print(str(n+1) + '. '+ text_generated['generated_text'].split(text)[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "643c6652",
   "metadata": {},
   "source": [
    "## nlpaug text generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5f92dde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'tokens': Can't extract `str` to `Vec`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDie Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m aug \u001b[38;5;241m=\u001b[39m nas\u001b[38;5;241m.\u001b[39mContextualWordEmbsForSentenceAug(model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxlnet-base-cased\u001b[39m\u001b[38;5;124m'\u001b[39m,max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m augmented_text \u001b[38;5;241m=\u001b[39m \u001b[43maug\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nlpaug\\base_augmenter.py:98\u001b[0m, in \u001b[0;36mAugmenter.augment\u001b[1;34m(self, data, n, num_thread)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAbstSummAug\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBackTranslationAug\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContextualWordEmbsAug\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContextualWordEmbsForSentenceAug\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(aug_num):\n\u001b[1;32m---> 98\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43maction_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    100\u001b[0m             augmented_results\u001b[38;5;241m.\u001b[39mextend(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nlpaug\\augmenter\\sentence\\context_word_embs_sentence.py:116\u001b[0m, in \u001b[0;36mContextualWordEmbsForSentenceAug.insert\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    113\u001b[0m     all_data \u001b[38;5;241m=\u001b[39m [data]\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_custom_api:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_custom_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_native_insert(all_data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nlpaug\\augmenter\\sentence\\context_word_embs_sentence.py:191\u001b[0m, in \u001b[0;36mContextualWordEmbsForSentenceAug._custom_insert\u001b[1;34m(self, all_data)\u001b[0m\n\u001b[0;32m    189\u001b[0m     results \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;241m+\u001b[39m a \u001b[38;5;28;01mfor\u001b[39;00m d, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(all_data, augmented_texts)]\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxlnet\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m--> 191\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_tokens_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmented_texts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nlpaug\\augmenter\\sentence\\context_word_embs_sentence.py:191\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    189\u001b[0m     results \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;241m+\u001b[39m a \u001b[38;5;28;01mfor\u001b[39;00m d, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(all_data, augmented_texts)]\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxlnet\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m--> 191\u001b[0m     results \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_tokens_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(all_data, augmented_texts)]\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:536\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.convert_tokens_to_string\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_tokens_to_string\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument 'tokens': Can't extract `str` to `Vec`"
     ]
    }
   ],
   "source": [
    "text = 'Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren.'\n",
    "aug = nas.ContextualWordEmbsForSentenceAug(model_path='xlnet-base-cased',max_length=200)\n",
    "\n",
    "augmented_text = aug.augment(text, n=3)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Texts:\")\n",
    "for i in augmented_text:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "415584c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren.\n",
      "Augmented Text:\n",
      "Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren. ' of to .\n",
      "Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren. at a is is : from - in - the ?\n",
      "Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren. to and that - the - - a as , .\n"
     ]
    }
   ],
   "source": [
    "aug = nas.ContextualWordEmbsForSentenceAug(model_path='gpt2')\n",
    "augmented_text = aug.augment(text, n=3)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "for i in augmented_text:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a792406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren.\n",
      "Augmented Text:\n",
      "Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren. M S It .\n",
      "Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren. s This R C D , - G I R This I the The The The of K E P M K Image A In T This G F This\n",
      "Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren. to In A V I The A : I s This D E K 1 This F E If - I S K .\n"
     ]
    }
   ],
   "source": [
    "aug = nas.ContextualWordEmbsForSentenceAug(model_path='distilgpt2')\n",
    "augmented_text = aug.augment(text, n=3)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "for i in augmented_text:\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04306552",
   "metadata": {},
   "source": [
    "## nlpaug paraphrasing\n",
    "https://nlpaug.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5407875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren.\n",
      "Augmented Text:\n",
      "['SCHUFA macht Schule bieten Lehrkräften fachliche und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren.']\n",
      "CPU times: total: 13.5 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "asa = nas.AbstSummAug(model_path='t5-base')\n",
    "text = 'Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren.'\n",
    "augmented_text = asa.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8f9fe26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.7 s\n",
      "Wall time: 7.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SCHUFA macht Schule bieten Lehrkräften fachliche und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "asa.augment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78b084dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren.\n",
      "Augmented Text:\n",
      "['Die Unterrichtsmaterialien des SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen Smart Material zur Finanzbildung. Da können in allen Art und berufsbildenden Schulen eingesetzt werden Sie eignen uns an die im Alter zwischen 15 und 20 Euro.']\n",
      "CPU times: total: 7.95 s\n",
      "Wall time: 8.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cwea = naw.ContextualWordEmbsAug(\n",
    "    model_path='roberta-base', action=\"substitute\")\n",
    "augmented_text = cwea.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e764df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.86 s\n",
      "Wall time: 4.75 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Die Unterrichtsmaterialien von 20 macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien mit einen Fall Unterricht zur Finanzbildung. Sie können man den Alter und berufsbildenden Schulen eingesetzt fest und eignen intern an Jugendliche im Alter zwischen 15 und 20 April.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cwea.augment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95f04a37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\kryst\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren.\n",
      "Augmented Text:\n",
      "['Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und twenty Jahren.']\n",
      "CPU times: total: 484 ms\n",
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86a42399",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nlpaug\\augmenter\\word\\synonym.py:66\u001b[0m, in \u001b[0;36mSynonymAug.__init__\u001b[1;34m(self, aug_src, model_path, name, aug_min, aug_max, aug_p, lang, stopwords, tokenizer, reverse_tokenizer, stopwords_regex, force_reload, verbose)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path \u001b[38;5;241m=\u001b[39m model_path\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang \u001b[38;5;241m=\u001b[39m lang\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43maug_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nlpaug\\augmenter\\word\\synonym.py:165\u001b[0m, in \u001b[0;36mSynonymAug.get_model\u001b[1;34m(cls, aug_src, lang, dict_path, force_reload)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nmw\u001b[38;5;241m.\u001b[39mWordNet(lang\u001b[38;5;241m=\u001b[39mlang, is_synonym\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m aug_src \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mppdb\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minit_ppdb_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdict_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_reload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maug_src is not one of `wordnet` or `ppdb` while \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is passed.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(aug_src))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nlpaug\\augmenter\\word\\synonym.py:22\u001b[0m, in \u001b[0;36minit_ppdb_model\u001b[1;34m(dict_path, force_reload)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m PPDB_MODEL \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force_reload:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PPDB_MODEL[model_name]\n\u001b[1;32m---> 22\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mnmw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPpdb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m PPDB_MODEL[model_name] \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nlpaug\\model\\word_dict\\ppdb.py:23\u001b[0m, in \u001b[0;36mPpdb.__init__\u001b[1;34m(self, dict_path)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_default_score_thresholds() \u001b[38;5;66;03m# TODO: support other filtering\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_synonym \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# TODO: antonyms\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nlpaug\\model\\word_dict\\ppdb.py:27\u001b[0m, in \u001b[0;36mPpdb._init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdict_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nlpaug\\model\\word_dict\\ppdb.py:36\u001b[0m, in \u001b[0;36mPpdb.read\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_path):\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[0;32m     38\u001b[0m             line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'data'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aug = naw.SynonymAug(aug_src='ppdb', model_path='data')\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "678f4dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31 s\n",
      "Wall time: 38.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Die Lehrmaterialien der SCHUFA macht Schule stellen Lehrern professionell und didaktisch gestaltete Materialien für einen kompetenzorientierten Unterricht zur Finanzerziehung zur Verfügung. Sie sind an allen allgemeinbildenden und berufsbildenden Schulen einsetzbar und für Jugendliche zwischen 15 und 20 Jahren geeignet.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#BEST\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nlpaug.augmenter.word as naw\n",
    "# text = \"FirmenWissen ist ein Angebot von Creditreform, dem europäischen Markt- und Qualitätsführer für Wirtschaftsinformationen. Die Vermittlung von Firmendaten ist seit über 15 Jahren unsere Mission. Im Kern lautet unser Auftrag: zuverlässige und aktuelle Firmeninformationen aufzubereiten, zu verknüpfen, gut durchsuchbar und exportierbar machen, um unseren Nutzern den entscheidenden Zeit- und Wissensvorsprung zu verschaffen. Mehr als 37 Millionen Seitenaufrufe in 2018 machen uns zur Nr. 1 für Firmeninformationen im deutschen Internet. Dabei setzen wir auf ein solides Fundament: Seit über 136 Jahren sorgt Creditreform durch seine Informationsbasis für ein risikofreies Miteinander in geschäftlichen Beziehungen. Rund 130.000 Unternehmen in Deutschland vertrauen auf die Leistungen von Creditreform.\"\n",
    "text = 'Die Unterrichtsmaterialien von SCHUFA macht Schule bieten Lehrkräften fachlich und didaktisch ausgearbeitete Materialien für einen kompetenzorientierten Unterricht zur Finanzbildung. Sie können in allen allgemeinen und berufsbildenden Schulen eingesetzt werden und eignen sich für Jugendliche im Alter zwischen 15 und 20 Jahren.'\n",
    "\n",
    "back_translation_aug = naw.BackTranslationAug(\n",
    "    from_model_name='facebook/wmt19-de-en',\n",
    "    to_model_name='facebook/wmt19-en-de', \n",
    ")\n",
    "back_translation_aug.augment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e00fb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 26 s\n",
      "Wall time: 24.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Die Lehrmaterialien der SCHUFA macht Schule stellen Lehrern professionell und didaktisch gestaltete Materialien für einen kompetenzorientierten Unterricht zur Finanzerziehung zur Verfügung. Sie sind an allen allgemeinbildenden und berufsbildenden Schulen einsetzbar und für Jugendliche zwischen 15 und 20 Jahren geeignet.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "back_translation_aug.augment(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8f77291-e260-46a8-89f7-2deeefa566d0",
   "metadata": {},
   "source": [
    "## Translate into specified lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10050283-3ff1-42b5-9a26-950672ca1d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 52.9 s\n",
      "Wall time: 36.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CompanyHouse ist Handelsregister- und Wirtschaftsinformationsportal. Mit über 8,5 Millionen Unternehmen und Führungskräften ist CompanyHouse die umfassendste kostenlose Quelle aktueller Unternehmens- und Wirtschaftsinformationen. Wir verknüpfen Daten aus öffentlichen Quellen über Unternehmen, Menschen und Märkte intelligent und unterstützen damit Klein- und Kleinstunternehmen beim Auf- und Ausbau ihrer Geschäftsbeziehungen. Geschäftsführer: Johannes Stoll, Dr. Ole Schröder, Tanja BirkholzBisherige Unterzeichner: Jens Holger Junak, Michael Glaßner, Brigitte Reiß, Andrea Störmann, Evelyn Koch 13.01.2023Neue Publikation: geändert13.01.2023Neue Registerunterlagen Historischer Handelsregisterauszug, chronologischer Handelsregisterauszug und aktueller Handelsregisterauszug nutzbar11.10.2022Neue Publikation: geändert21.09.2022Neue Eigentumsinformationen veröffentlicht am 02.08.2022'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import FSMTForConditionalGeneration, FSMTTokenizer\n",
    "mname = \"facebook/wmt19-en-de\"\n",
    "tokenizer = FSMTTokenizer.from_pretrained(mname)\n",
    "model = FSMTForConditionalGeneration.from_pretrained(mname)\n",
    "\n",
    "text = '''CompanyHouse is commercial register and business information web portal. With over 8.5 million companies and executives, CompanyHouse is the most comprehensive free source for up-to-date company and business information. We intelligently link data from public sources about companies, people and markets and thus support small and micro-enterprises in establishing and expanding their business relationships.              \n",
    "              \n",
    "Managers:\n",
    "Johannes Stoll, Dr. Ole Schröder, Tanja Birkholz\n",
    "Previous signatories:\n",
    "Jens Holger Junak, Michael Glaßner, Brigitte Reiß, Andrea Störmann, Evelyn Koch \n",
    "              \n",
    "13.01.2023\n",
    "New publication: change\n",
    "13.01.2023\n",
    "New register documents Historical commercial register extract, chronological commercial register extract and current commercial register extract available\n",
    "11.10.2022\n",
    "New publication: change\n",
    "21.09.2022\n",
    "New ownership information released\n",
    "02.08.2022\n",
    "'''\n",
    "# Change in creditworthiness due to new credit limit bar\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids)\n",
    "de_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "de_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d585ef56-116f-4535-a11b-a64665f9548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add input from user to translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700fc15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
